{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "StrongLensingChallenge-Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github//ML4SCI/ML4SCIHackathon/blob/main/GravitationalLensingChallenge/StrongLensingChallenge-Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VRDRHc9N3gY"
      },
      "source": [
        "# Strong Lensing Challenge - Regression\n",
        "\n",
        "Since its discovery via its gravitational interactions over half a century ago, the identity of dark matter has yet to be found. This is despite countless experiments aimed at detection of the most promising dark matter candidates. An alternative to terrestial detection (for example, with colliders or liquid xenon) for dark matter identification is unique gravitational signatures which arise from disparte substructure predicitions among dark matter models. Example substructures include subhalos of WIMP-like cold dark matter and vortices of superfluid dark matter. Perhaps the most promising method to infer the unique morphology of these substructures is with strong galaxy-galaxy lensing images; an intermediate dark matter halo (which contains a visible galaxy) lenses a galaxy which is behind it.\n",
        "\n",
        "In this challenge we will use regression to measure the total fraction of mass in substructure of a dark matter halo. We will do so utilizing simulated strong lensing images with subahlo substructure consistent with non-interacting cold dark matter models.\n",
        "\n",
        "In this notebook, we present a simple model implemented using the PyTorch library to solve a regression task for strong lensing images. Specifically, the task is to learn the total fraction of mass in substructure of a dark matter halo, i.e. $f_{sub} = m_{sub}/m_{halo}$ where $m_{sub}$ is the mass in substructure and $m_{halo}$ is the mass of the dark matter halo.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "The dataset consists of *simulated* strong lensing images with cold dark matter subhalos generated by PyAutoLens. It contains 25k grayscale images with the size of 150x150 and the corresponding $f_{sub}$ which is known from simulations and should be $\\sim \\mathcal{O}(1\\%)$.\n",
        "\n",
        "\n",
        "### Evaluation Metric\n",
        "\n",
        "* MAE (Mean Absolute Error)\n",
        "\n",
        "### Instructions for using the notebook\n",
        "\n",
        "1. Use GPU acceleration: (Edit --> Notebook settings --> Hardware accelerator --> GPU)\n",
        "2. Run the cells: (Runtime --> Run all)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZOWhYDonG1y"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZjIqhKTN3gk"
      },
      "source": [
        "!gdown http://drive.google.com/uc?id=1hu472ALwGPBcTCXSAM0VoCWmTktg9j-j\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC1KGr6ujaNF"
      },
      "source": [
        "!tar zxvf lens_data_alt.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1mBBgdCcGbi"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZsZ8IY2ndlj"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU5PZDiSVhWx"
      },
      "source": [
        "DATASET_PATH = './lens_data'\n",
        "images = []\n",
        "# f_sub -> mass fraction\n",
        "f_subs = []\n",
        "for f_name in os.listdir(DATASET_PATH):\n",
        "  img, mass = np.load(os.path.join(DATASET_PATH,f_name),allow_pickle=True)\n",
        "  # Add img and mass to separate lists\n",
        "  # Add 1 as the first dimension for image\n",
        "  images.append(img.reshape(1,img.shape[0],img.shape[1]))\n",
        "  # Convert mass to a single element array with (1,1) dimensions\n",
        "  f_subs.append(np.array(mass,ndmin=1))\n",
        "\n",
        "# Images shape is (num_of_images,1,150,150)\n",
        "images = np.stack(images).astype('float32')\n",
        "# Mass fractions shape is (num_of_images,1)\n",
        "f_subs = np.stack(f_subs).astype('float32')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-jlHIGDnq-C"
      },
      "source": [
        "## Plot Strong Lensing Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G31lf1Imbqg8"
      },
      "source": [
        "# Will plot only first 4 lenses \n",
        "grid_size = (5,5)\n",
        "figure,axis = plt.subplots(grid_size[0],grid_size[1],figsize=(15,15),sharey=True)\n",
        "img_indx=0\n",
        "\n",
        "for i in range(grid_size[0]):\n",
        "  for j in range(grid_size[1]):\n",
        "    # Plotting image\n",
        "    img = axis[i][j].imshow(images[img_indx][0], cmap='binary', origin='lower')\n",
        "    # Setting up a title\n",
        "    axis[i][j].set_title(f'f_sub: {f_subs[img_indx][0]:.2}')\n",
        "    # Plotting a colorbar to show the intensity of pixels\n",
        "    plt.colorbar(img,ax=axis[i][j],fraction=0.046, pad=0.04)\n",
        "\n",
        "    img_indx+=1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIZLhj8ToCCS"
      },
      "source": [
        "## Standardization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18zWNYYMqrQC"
      },
      "source": [
        "# Applies z-standartization to make the dataset mean=0 and std=1\n",
        "def standardize(element,STD,MEAN):\n",
        "    return (element - MEAN) / STD\n",
        "# Cancel the effect of z-standartization\n",
        "def inv_standardize(element,STD,MEAN):\n",
        "    return element * STD + MEAN\n",
        "\n",
        "# Find stats of the dataset\n",
        "IMAGES_MEAN, IMAGES_STD = images.mean(), images.std()\n",
        "F_SUB_MEAN, F_SUB_STD = f_subs.mean(), f_subs.std()\n",
        "\n",
        "# Standardize the dataset\n",
        "images=standardize(images,IMAGES_STD,IMAGES_MEAN)\n",
        "f_subs=standardize(f_subs,F_SUB_STD,F_SUB_MEAN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tTzO9y0oQfh"
      },
      "source": [
        "## Create Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjkdENfSnHlm"
      },
      "source": [
        "class RegressionNumpyArrayDataset(Dataset):\n",
        "  def __init__(self,x,y,indexes=None,x_transforms_func = None):\n",
        "\n",
        "    self.x = x[indexes]\n",
        "    self.y = y[indexes]\n",
        "\n",
        "    # Transforms that will be aplied to the every batch of lenses.\n",
        "    # x_transforms_func must be callable.\n",
        "    self.x_transforms = x_transforms_func\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    # Returns the length of the dataset\n",
        "    return self.x.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # Returns an (image, label) tuple\n",
        "    image, label = self.x[idx], self.y[idx]\n",
        "    \n",
        "    # Convert to Tensor and Float\n",
        "    image = torch.tensor(image).float()\n",
        "    label = torch.tensor(label).float()\n",
        "\n",
        "    # Apply transforms\n",
        "    if self.x_transforms!=None:\n",
        "      image= self.x_transforms(image)\n",
        "\n",
        "\n",
        "    return  image , label "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KM96cNmoVOk"
      },
      "source": [
        "## Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UApWaimocgBk"
      },
      "source": [
        "train_indx = np.arange(0,15000)#np.arange(0,13000)\n",
        "test_indx = np.arange(15000,20000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_aFGyOcpEIN"
      },
      "source": [
        "## Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVLyBJlspRp9"
      },
      "source": [
        "base_image_transforms = transforms.Compose([\n",
        "    transforms.Resize(150)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZykEbpCpRsn"
      },
      "source": [
        "# Create instanses of test and train datasets\n",
        "train_dataset = RegressionNumpyArrayDataset(images, f_subs, train_indx,\n",
        "                                            base_image_transforms)\n",
        "test_dataset = RegressionNumpyArrayDataset(images, f_subs, test_indx,                                 \n",
        "                                           base_image_transforms)\n",
        "\n",
        "# Create instanses of dataloaders\n",
        "batch_size = 64\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_77B1xJqsE-O"
      },
      "source": [
        "## Regression Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ob1RvVNsnXo"
      },
      "source": [
        "class LinearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flat dimensions before applying the linear layer\n",
        "        flatten_x = torch.flatten(x,start_dim=1)\n",
        "        out = self.linear(flatten_x)\n",
        "        return out\n",
        "\n",
        "class Resnet18Regression(torch.nn.Module):\n",
        "    def __init__(self, num_of_input_channels, output_size):\n",
        "        super(Resnet18Regression, self).__init__()\n",
        "        self.resnet18 = torchvision.models.resnet18()\n",
        "        # Change the input number of channels to 1 to make it work on grayscale images\n",
        "        self.resnet18.conv1 = torch.nn.Conv2d(num_of_input_channels, 64, kernel_size=(7, 7), \n",
        "                                 stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        # Change the output size to 1 to predict a mass density\n",
        "        self.resnet18.fc = torch.nn.Linear(in_features=512, out_features=output_size, \n",
        "                                           bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.resnet18(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfENrnhVsJXq"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk-CIC5vwUEJ"
      },
      "source": [
        "def mse_loss(pred, true):\n",
        "    loss = (pred-true).pow(2)\n",
        "    return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acsonAyTsPm1"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1p5Oi2mwV0B"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Device: {device}')\n",
        "\n",
        "# Create an instanse of the model.\n",
        "# 150*150 = 22500\n",
        "#model = LinearRegression(22500,1).to(device)\n",
        "model = Resnet18Regression(1,1).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpjAFrWbsJta"
      },
      "source": [
        "# Optimizer\n",
        "lr = 3e-4\n",
        "weight_decay = 0\n",
        "num_of_epochs = 40\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zSkoo9h9mEH"
      },
      "source": [
        "# Start the training loop\n",
        "for i in range(num_of_epochs):\n",
        "  epoch_loss = 0\n",
        "  num_of_steps_in_epoch = 0\n",
        "  for step, (images_batch, f_subs_batch) in enumerate(train_data_loader):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Use GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "      images_batch = images_batch.cuda()\n",
        "      f_subs_batch = f_subs_batch.cuda()\n",
        "\n",
        "    # RUN the model\n",
        "    predicted_f_subs = model(images_batch)\n",
        "    \n",
        "    # Calculate loss\n",
        "    loss = mse_loss(predicted_f_subs,f_subs_batch)\n",
        "\n",
        "    # Calculate gradient\n",
        "    loss.backward()\n",
        "    # Do an optimization step\n",
        "    optimizer.step()\n",
        "\n",
        "    \n",
        "    epoch_loss+=loss\n",
        "    num_of_steps_in_epoch+=1\n",
        "  \n",
        "  loss_w = (epoch_loss/num_of_steps_in_epoch).detach().item()\n",
        "  print(f'Epoch {i+1} loss is: {loss_w}')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prJ8ZZWnsq9-"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVlSQo7cFEBC"
      },
      "source": [
        "# Run the model on the test dataset\n",
        "predicted_f_subs_list = []\n",
        "real_f_subs_list = []\n",
        "for step, (images, f_subs) in enumerate(test_data_loader):\n",
        "    # Use GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "      images = images.cuda()\n",
        "      f_subs = f_subs.cuda()\n",
        "\n",
        "    # RUN the model\n",
        "    predicted_f_subs = model(images)\n",
        "    predicted_f_subs_list.append(predicted_f_subs.cpu().detach().numpy())\n",
        "    real_f_subs_list.append(f_subs.cpu().numpy())\n",
        "\n",
        "\n",
        "# Remove the last batch of the results to make all the arrays in the list the same size\n",
        "del predicted_f_subs_list[-1]\n",
        "del real_f_subs_list[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CWrGQBwH0XA"
      },
      "source": [
        "# Mean Absolute Error is used as the main metric for measuring the performance of the model.\n",
        "def mae_loss(pred, true):\n",
        "    loss = np.abs(pred-true)\n",
        "    return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wea5l0v3tw2t"
      },
      "source": [
        "## Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eldE1M71GESz"
      },
      "source": [
        "# PLOTTING TEST RESULTS\n",
        "predicted_f_subs_arr = np.concatenate(predicted_f_subs_list)\n",
        "real_f_subs_arr = np.concatenate(real_f_subs_list)\n",
        "\n",
        "m_pred,m_true = inv_standardize(predicted_f_subs_arr,F_SUB_STD,F_SUB_MEAN),inv_standardize(real_f_subs_arr,F_SUB_STD,F_SUB_MEAN)\n",
        "\n",
        "\n",
        "\n",
        "test_mae = mae_loss(m_pred,m_true)\n",
        "plt.figure(figsize=(8,8),dpi=80)\n",
        "plt.scatter(m_true, m_pred,  color='black')\n",
        "line = np.linspace(0, 0.3, 10)\n",
        "plt.plot(line, line)\n",
        "plt.xlabel('Observed mass fraction')\n",
        "plt.ylabel('Predicted mass fraction')\n",
        "print(f'MAE: {test_mae}')\n",
        "#plt.text(1,4, 'MAE: {:.4f}'.format(test_mae))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM_WXCn-uTzM"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJr_5jdxGam1"
      },
      "source": [
        "SAVE_PATH = './best_model'\n",
        "torch.save(model.state_dict(), SAVE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BamiXkTN3hH"
      },
      "source": [
        "## Submission Guidelines \n",
        "\n",
        "* You are required to submit a Google Colab Jupyter Notebook clearly showing your implementation along with the evaluation metrics (MAE) for the training and validation data.\n",
        "* You also have to submit the final trained model, including the model architecture and the trained weights ( For example: HDF5 file, .pb file, .pt file, etc. )\n",
        "* You can use this example notebook as a template for your work.\n",
        "+ The model performance will be evaluated on the hidden dataset based on the above metrics. \n",
        "\n",
        "> **_NOTE:_**  You are free to use any ML framework such as PyTorch, Keras, TensorFlow, etc."
      ]
    }
  ]
}
